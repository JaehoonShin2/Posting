# AWS Cloud Practitioner Essentials 교육

`Cloud Practitioner` 는 AWS 의 자격증 중 하나.

### AWS 자격증

영역

- 클라우드 개념 26%
- 보안 및 규정 준수 25%
- 기술(AWS 의 서비스들) 33% — 오늘은 이 중에서 핵심 서비스(IaaS) 들을 학습
    - 컴퓨터 서비스, 네트워크 서비스, DB 서비스, 모니터링 서비스, 보안 서비스
- 결제 및 요금 16%

시험 세부 정보

- 문항은 65문항
- 최소 합격 점수는 720/1000
- 시험 비용은 100USD
- 시험 시간은 90분이고, 비영어권 신청 시 30분의 시험 시간이 연장된다.
- 시험은 객관식 및 선다형 문항
- 자격증의 유효 기간은 3년이고, 기간이 지나면 재시험을 봐야 한다.

### 1. AWS 소개(영역3)

### 클라우드 컴퓨팅이란?

컴퓨터 리소스를 인터넷을 통해 서비스로 사용할 수 있는 주문형 서비스

- 온디맨드(IT 리소스-서버, 어플리케이션의 배포-가 필요할 때)로 서비스에 엑세스
- 대규모 사전 투자 방지(리소스를 탄력적으로 컨트롤 할 수 있다)
- 필요에 따라 컴퓨팅 리소스 프로비저닝
    - 프로비저닝 : 사용자의 요구에 맞게 시스템을 할당, 배치, 배포해 두었다가 필요 시 시스템을 즉시 사용할 수 있는 상태로 준비해두는 것
- 사용한 만큼만 비용 지불(종량제)

### 클라우드 컴퓨팅 배포 모델

1. 클라우드(== 퍼블릭 클라우드)
    
    IT 리소스를 제공하는 제공자와 이를 사용하는 사용자가 일치하지 않는 것. 즉 누구든지 IT 리소스가 필요하면 제공자에게서 필요한 리소스를 사용할 수 있는 것
    
    고객 입장에서는 클라우드 제공자가 제공하는 수많은 서비스들을 이용할 수 있다는 장점이 있다.
    
    클라우드 네이티브 어플리케이션 : 클라우드가 제공하는 이점을 최대한 활용하고 있는 어플리케이션. 
    
    - IaaS : 서버와 스토리지 등을 사용자에게 제공
    - Paas : IaaS + OS ..
    - SaaS : 완성된 소프트웨어를 제공

1. 온프레미스(== 프라이베이트 클라우드)
    
    IT 리소스를 제공하는 제공자와 사용자가 일치한다. 즉 해당 물리적인 서버의 주인은 A회사이고, 사용자는 A 회사의 관계자만이 사용이 가능하다.
    
    물리적인 호스트가 존재하고, 해당 호스트에 OS 을 올리는 1~2세대 가상화 방식이 아니다. 
    
    물리적인 하드웨어를 가지고 직접 IT 리소스를 배포하기보다는 대부분의 온프레미스는 CPU, 네트워크, 스토리지를 가상화해서 더이상 물리적 하드웨어에 접근하지 않고 가상화된 레이어를 통해 내가 필요한 서버를 내가 직접 만들어서 사용한다.
    

가상화 및 리소스 관리 툴을 사용해 리소스 배포.

어플리케이션 관리 및 가상화 기술을 사용해 리소스 사용량 증가

기존의 온프레미스의 하드웨어를 가상화하였기 때문에, HVM 방식으로 OS 입장에서는 바로 호스트 OS 에 접근이 가능해지고, 굳이 하드웨어까지 가지 않더라도 사용자가 원할 때 HVM 을 설치하고 삭제할 수 있다.

1. 하이브리드(== 하이브리드 클라우드)
    
    필요에 따라서 클라우드와 온프레미스를 함께 사용하는 환경. 즉 어플리케이션마다 적합한 배포환경을 선택해서 함께 사용하는 환경
    
    클라우드 기반 리소스를 온프레미스 인프라에 연결.
    
    클라우드 기반 리소스와 레거시 IT 어플리케이션 연계
    

### 클라우드 컴퓨팅의 이점

1. 비용의 측면
    - 가변비용

**클라우드(=가변비용)**

초기 투자 없이, 사용한 만큼만 비용을 지불하면 된다.

즉 클라우드는 가변비용만 지불하면 된다.

다만, 클라우드의 절대적인 서비스 비용이 저렴하지는 않다는 것은 고려해야 한다.

**온프레미스(고정+초기비용)**

IT 리소스를 사용하기 전에 건물 대여 비용, 서버 대여 혹은 구매 비용 등 초기 투자가 필요하다.

또한 온프레미스는 고정비용+가변비용으로 비용이 발생한다.

고정비용이란, 온프레미스가 가지고 있는 모든 서버를 구동하는데 소모되는 비용이 발생한다. 설령 해당 서버가 실제로 사용되지는 않더라도 언제 서버가 피크에 도달할 지 모르기 때문에 서버가 가동되고 있어야 하기 때문이다.

- 비용 최적화
    
    매달 청구되는 비용을 확인하면서, 사용되는 비용을 최적화 할 수 있다. 즉 불필요하게 사용되었던 비용을 줄이는 과정이 가능하다.
    

- 규모의 경제
    
    AWS, Google Cloud Platform, Naver Cloud Platform 과 같이 막대한 규모의 서버를 구축하게 되면 서버 구축의 단위 비용이 줄어들게 된다. 이는 사용자에게 청구되는 비용의 감소로 이어진다.
    

1. 용량의 측면(탄력성)
    - 탄력성
        
        매 달, 매 순간 필요로 하는 용량이 다르다. 그런데 온프레미스는 최고 피크를 기준으로 리소스를 갖추어야 한다. 하지만 클라우드를 사용하게 되면 사용되는 만큼의 리소스만이 사용되기 때문에 잉여자원으로 남게 되는 용량(리소스) 가 줄게 된다. 
        
    
2. 속도 및 민첩성
    
    리소스의 추가가 필요해질 경우, 해당 리소스를 확보하기 위해서 온프레미스는 상대적으로 오랜 시간이 걸리게 된다. 반면 클라우드의 경우 즉각적으로 확보를 할 수 있다.
    

1. Globalization
    
    AWS 글로벌 인프라를 이용해서 어플리케이션을 전 세계에 빠르게 배포가 가능하다.
    

### 2. 클라우드 컴퓨팅(영역3)

compute resource : cpu, memory. 

해당 resource가 필요한 이유는 task를 실행해보기 위함.

소스코드를 실행해봄으로써(어플리케이션을 구동) task 를 실행해본다.

![img1.daumcdn.jpg](AWS%20Cloud%20Practitioner%20Essentials%20%E1%84%80%E1%85%AD%E1%84%8B%E1%85%B2%E1%86%A8%20a9a38f4cd01745b49318d5aa8da97141/img1.daumcdn.jpg)

 

어떤 어플리케이션을 실행하기 위해서는 리소스, OS, 런타임 라는 인프라가 있어야만 가능하다. 

### EC2(Elastic Cloud Compute Cloud)

`EC2` 는 AWS 에서 제공하는 클라우드 가상 서버이다.

**서버** 라고 부른 이유는 클라이언트로 쓰기 보다는 어떤 서비스를 제공하기 위한 용도로 쓰인다. 웹서비스일 수도, DB 서비스, 메일 서비스… EC2 서버 위에 웹서버를 올릴 수도 있고, DB 서버를 올릴 수도 있다. 즉 서버들은 각각의 서버가 요구되어지는 성능 사항이 있다.

CPU, Memory, network 등등… 각각의 어플리케이션마다 필요로 하는 성능이 다르다. 따라서 가상 서버에 배포될 서버(서비스)마다 필요로 하는 리소스를 선택적으로 생성할 수 있다. AWS 는 각각의 어플리케이션들을 위한 최적의 EC2 를 만들기 위해 인스턴스 유형을 제공한다.

다만, task 를 실행하다가 cpu 나 memory 의 필요 정도에 따라서 고객이 수동으로 조작이 필요하고, OS 적으로도 변경이 필요하다면 수동으로 변경이 필요하다. 즉 고객이 직접 관리가 필요하다.

**Lambda**

그런데 고객이 단순히 task 실행만을 원할 때(서버 구축 및 관리를 배제하고) 

서버 리스하게 컴퓨팅 리소스를 제공하는 서비스도 존재한다. 

이를 `Lambda` 서비스라고 한다.

EC2 를 생성할 때, OS 이미지를 Amazon machine Image 로 제공한다.

인스턴스의 상태가 `실행중` 으로 표시되면 해당 OS 가 부팅이 된 상태(== 과금상태) 이다.

EC2 에 연결한다는 의미는, 부팅된 OS 에 접속하는 것을 의미한다. 

### EC2 인스턴스 유형

ex) t2.mirco 라는 이름이 있다면, 

`t` 는 인스턴스의 타입

`2` 는 세대를 의미

`[a, g..]` 등은 옵션을 의미

`micro` 는 size 를 의미한다.

1. 범용(t, m) : 컴퓨팅, 메모리, 네트워킹 리소스를 균형 있게 제공
2. 컴퓨팅 최적화(c) : 고성능 프로세서를 제공해서 컴퓨팅 집약적 어플리케이션 작업에 적합
3. 메모리 최적화(r, z, x) : 고성능 데이터베이스에 적합
4. 엑셀러레이티드 컴퓨팅(g, p ,h) 하드웨어 가속기를 이용해 데이터 처리를 가속화
5. 스토리지 최적화(d, i) : 분산 파일 시스템 및 데이터 웨어하우징 어플리케이션 작업에 적합

이미 생성한 인스턴스는 유형을 변경 할 수 있는데, 이를 위해서는 현재 실행중인 인스턴스를 멈춘 뒤, 해당 인스턴스의 설정에서 유형을 변경할 수 있다.

### EC2 결제 옵션

- 프리티어
    
    초기 회원 가입 후 1년 간 특정 서비스의 특정 조건 하에 무료로 서비스를 제공
    
    ex) EC2 의 경우 linux/window OS 의 t2.micro / t3.micro 두 가지 인스턴스 유형을 사용하는 것에 대해서 1달 750 시간 내외로 무료 이용이 가능하다.
    

- 온디맨드(종량제)
    
    시간당/초당 사용량을 계산
    
    초기 선결제 비용이나 최소 약정이 없다. 
    
    불규칙한 단기 워크로드에 적합하다.
    
    네트워크 비용 따로, 스토리지 비용 따로 청구된다. EC2 비용은 CPU 에 대한 비용이다.
    
    동일한 EC2 라 할 지라도 어느 리전을 사용하느냐에 따라서 단위 가격이 달라진다.
    
- 스팟
    
    리소스 중에는 유휴 리소스(예비용으로 남겨놓은 리소스) 가 존재하는데, 이 부분을 저렴하게 제공하는 방식.
    
    온디맨드 대비 비용이 저렴하지만, 언제든지 인스턴스가 회수 당할(강제 종료) 위험이 있다.
    
    시작 및 종료 시간이 자유로운 워크로드에 적합하다.
    

- PI(수량)
    
    1년 혹은 3년의 약정을 걸어서 EC2 인스턴스를 유지하는 방법. 몇 대의 EC2 를 유지할 지에 맞춰서 결제하는 방식
    

- Savings plans
    
    1년 혹은 3년 약정을 걸어서 사용하는 방식으로, EC2 의 지속시간을 몇 시간동알 유지할지에 맞춰서 결제하는 방식
    

shared tenent 

하나의 물리적 호스트 위에 여러 개의 인스턴스가 올라가게 된다.

EC2 전용 컴퓨팅

- 전용 인스턴스
    
    단일 고객용 하드웨어의 VPC 에서 실행되는 EC2 인스턴스.
    
    표준 EC2 인스턴스에 비해 더 높은 비용
    
- 전용 호스트
    
    단일 고객용 EC2 인스턴스 용량을 갖춘 물리적 서버.
    
    가장 비용이 많이 드는 EC2 옵션. 
    
    클라우드에서 온프레미스와 같이 물리적 서버를 줄 수는 없지만, 마치 EC2 가 호스트인 것 처럼 구성하는 방식.
    

### EC2 Auto Scaling

1개의 EC2(웹서버) 만 가지는 것이 아니라 복수의 EC2 를 가지고서 1번 서버의 부하나 에러에 대해서 2번 서버에 작업을 분배하거나 대체 서버로 작동하는 것

Scale out : EC2 를 필요에 따라서 확장해나가는 것

Scale in : EC2 를 필요에 따라 줄여나가는 것 

이러한 Scale 을 수동적으로 확장/축소를 시켜갈 수도 있지만, 민첩하게 수요에 따른 반응이 어렵다.

`Auto Scaling` 이란 Scale out/in 작업을 AWS 가 제공해주는 서비스

**Auto** 라고 해서 AWS 가 자의적인 판단을 가지고 Scaling 작업이 이루어지는 것은 아니다. 사용자가 설정을 해놓으면, 그 설정에 따라서 Scale 작업을 진행한다.

- 스케쥴 : 오전 2~6시 사이에는 Scale 축소… 또는 주말에는 Scale 확장과  같이 스케쥴에 맞춰 설정을 해놓는 방식
- metric : 실시간 메트릭 값들을 반영해서 사용자가 설정한 임계값 이상일 경우 확장/축소 등의 작업을 진행한다.

확장/축소 시 minimum scale 값, maximum scale 값, dafult scale 값을 설정할 수 있다.

Auto Scale 을 통해서 서버가 빈번하게 확장/축소된다면, 클라이언트 입장에서는 서버를 찾아가기 힘들다. 

따라서 서버로 하여금 1번이든 2번이든 3번이든 현재 이 클라이언트가 요청한 서비스를 제공할 서버를 연결 짓기만 하면 된다.

이 것을 제공하는 서비스의 이름이 ELB, `Elastic Load Balancing` 이다.

### Elastic Load Balancing

둘 이상의 가용영역에서 EC2 인스턴스, 컨테이너, IP 주소 등을 여러 대상ㅇ에 걸쳐 수신되는 트래픽을 자동 분산하는 서비스

클라이언트의 요청을 자동으로 확장된 서버를 discover 할 수 있다. 실제 서버의 상태나 갯수랑 상관없이 현재 서비스를 제공해줄 수 있는 서버로 분산시켜준다.

인스턴스 유형은 관리자가 선택해서 만들었다. 또한 OS Image 역시 선택해서 만든다.

관리자는 OS 에 접속해 어플리케이션을 실행, 배포한다.

즉 하드웨어만 가지고선 실행이 불가능하다. 어플리케이션을 실행하기 위해 리소스 관리, OS 관리 등의 작업이 필요로 해진다.

어플리케이션을 실행하기 위한 인프라(하드웨어, OS, 런타임) 를 관리하지 않고, 내가 원하는 어플리케이션을 실행하는 서비스를 실행하고 싶다면 `서버리스 컴퓨팅` 서비스를 사용할 수 있다. 

**서버리스 컴퓨팅**

- 서버를 프로비저닝하거나 관리하지 않고 코드를 실행.
- 코드가 실행되는 컴퓨팅 시간에 대해서만 비용을 지불(특정 이벤트가 발샐할 때)
    
    ex) 이미지가 업로드되면 고해상도/저해상도 이미지를 각각 만들어 저장하는 작업.. 해당 작업이 이루어질 때만 서버리스 컴퓨팅을 이용한다.
    
- 다른 AWS 서비스를 사용해 코드를 자동으로 트리거

AWS 에는 `Lambda` 서비스가 있다.

즉 Lambda 서비스는 상시로 작동되는 것이 아니다!!! 

### 3. 글로벌 인프라 및 안정성(영역2)

### 리전(Region)

리전은 두 가지 의미를 가진다.

1) AWS 에서 가지고 있는 물리적 데이터 센터의 위치를 의미

2) AWS 서비스가 배포되는 기준 지역. 만약 서울 리전으로 선택하고 여러 서비스를 사용하였다면, 해당 서비스들이 배포되는 지역은 서울 리전이 된다.

사용자는 다음 4가지를 기반으로 서비스, 데이터 및 어플리케이션에 적합한 리전을 결정하게 된다.

- 데이터 거버넌스 및 법적 요구사항 준수(나라마다 법적 사항들이 다를 수 있다)
- 고객과의 근접성(내가 만든 서비스를 최종적으로 사용하는 고객이 어디에 위치하는지를 중심으로 결정)
- 리전 내에서 사용 가능한 서비스(리전마다 제공하는 서비스의 종류가 다르다)
- 요금(리전마다 시간 당 비용이 다르다)
    
    나라마다 서비스 단위 가격이 다르다. 특히 나라마다 전기세에 영향을 많이 받는다.
    

### 가용영역(Availability Zone)

리전 내에는 2개 이상의 가용영역이 존재한다. 가용영역은 리전 내에서 100km 내에서 간격을 두고 존재하고 있다. 

또한 하나의 가용영역 내에도 간격을 두고 여러 데이터 센터가 존재한다. 간격을 두는 이유는 하나의 데이터 센터가 사용이 불가능해졌을 때(지진이나 태풍, 허리케인 등 자연재해나 인재 등), 대처 하기 위함이다.

사용자가 선택할 수 있는 건 리전과 가용영역까지이다. 가용영역 내에서 어떤 데이터센터가 선택되어 저장되어질 지는 선택할 수 없다.

따라서 사용자가 선택한 1a 라는 가용영역 내에서만 데이터 센터가 순환된다. 내가 사용하고 있는 1a 의 ‘가’ 라는 데이터 센터가 고장났다면 수 분 이내에 ‘나’ 데이터 센터로 바뀌게 된다. 하지만 만약 1a 의 모든 데이터 센터가 고장-사용불가- 이 났을 경우, 다른 가용영역(2a 와 같은) 으로 변환되지는 않는다.

하나의 서버는 죽을 수 있지만 우리의 서버는 가용성이 높아야 한다. 

즉 다중 가용 영역에 걸쳐서 서버를 배포할 수 있다. 1a 가용영역과 2a 가용영역에 배포하게 된다.

워크로드를 하나의 서버에만 두는 것이 아니라 다중 가용 영역을 활용한 아키텍팅을 한다.

### 엣지 로케이션(Edge Location)

internet 과 aws 서비스의 경계선에 존재하는 데이터 센터이다.

해당 데이터 센터를 통해서, 인터넷을 통한 DDOS 공격과 같은 보안에 관련된 부분을 보안하고, DNS 서비스도 올라가고, CloudFornt (CDN) 도 제공한다.

**CDN(**content delivery network)

미디어 서버를 서울에 만들면 전 세계 사람들이 모두 엑세스 가능하다. 근데 미국에 있는 사람이 해당 미디어 서버에 접근하려면 서울 리전까지 접속을 해야 한다. 이는 레이턴시의 발생이 존재할 수 있다.

이를 보완하기 위해 최종 사용자에게서 가장 가까운 엣지 로케이션에 캐시를 시켜놓는 것이다.

오리진 컨텐츠에 접속해야 하는 사용자는 서울 리전이 아니라 미국 CDN 에 저장된 캐시를 기반으로 서비스에 접근을 하게 하는 것이다.

### AWS 서비스와 상호 작용

- AWS management console 을 이용한 방법

인스턴스의 갯수가 적을 경우에는 간단하고 보기 쉽게 가능하다.

다만, 수십 ~ 수백 개의 인스턴스를 수정할 경우에는 불필요한 반복이 발생할 수 있다.

- AWS CLI

AWS 에서 제공하는 CLI 공부가 필요하다.

- 소프트웨어 개발 키트(SDK)

기존의 언어(자바, 파이썬…) 를 이용해서도 AWS 클라우드에 접속이 가능하다.

### 네트워킹(영역3)

EC2 는 ‘어느’ 네트워크에 연결하면 EC2 가 누구와 통신하는지 결정된다. 즉 워크로드를 배포하기 전에 이미 네트워크가 정의되어 있어야 한다.

네트워크를 정의한다? 의미는?

web - was - db 

각각의 서버를 연결하는 방식

외부로부터 web 은 접근하지만, was나 db 는 접근하면 안된다.

web 은 was 와 통신하고

was 는 db 와 통신한다.

하지만 web 이 db 와 통신할 필요는 없다.

외부에서 네트워크까지 와야 한다는 것은 같은 네트워크에 붙어있는 was 나 db 에도 접근이 가능해져버린다는 의미

따라서 하나의 네트워크를 쪼갤 필요가 있다. 그것을 서브넷 이라고 한다.

외부에서의 네트워크 접근 시에는 서브넷 마스크를 이용하고, 해당 서브넷에서 was 의 서브넷으로 이동할 때에는 막을 수 있다.

물리적인 호스트들을 물리적인 네트워크로 연결되어 있다. 고객들이 aws 클라우드에 접속해서 A 라는 고객과 B라는 고객이 있다.

A고객 : 3 tier 구조를 원함

B고객 : 3 tier 구조를 원함

고객이 배포한 워크로드들이 같은 호스트(물리적 서버)에 올라갈 수도 있다. 

즉 AWS 의 물리적 네트워크가 어떻게 되어 있던 간에 A 와 B 는 공유되지 않는다. AWS 는 네트워크조차 가상화되어 있다. 따라서 A 워크로드의 네트워크를 정의해야 한다. 이를 `virtual network cloud(VPC)` 라고 한다.

서브넷 1, 서브넷2, 서브넷3 과 같이 네트워크를 쪼개서 사용하면 된다.

우리가 배포할 네트워크가 있어야 하고, 이 네트워크를 직접 정의하는 것이다. 이를 `VPC` 라고 한다.

VPC = 고객의 워크로드를 배포하기 위해 고객의 정의한 네트워크 

서브넷은 격리된 리소스 그룹을 배치할 수 있는 VPC 의 섹션.

서브넷 중에서 인터넷과 통신하는 서버는 퍼블릿 서브넷으로 연결하고, 인터넷과 통신하면 안되는 서버는 프라이빗 서브넷으로 연결하는 방식.

같은 VPC 의 같은 서브넷을 가지고 있는 서버들은 통신이 가능하다.

같은 VPC 의 다른 서브넷을 가지고 있는 서버들도 통신이 가능하다.

그런데 VPC 안의 서브넷들은 내부에서만 통신하지 않고, 

1) 같은 AWS 클라우드의 또다른 VPC 와도 통신할 수도 있다.

2) 인터넷의 누군가와도 통신을 할 수 있다.

3) 기존의 온프레미스 DB 와도 통신할 수 있다.

=====

1. 경로를 만든다
2. Routing table 에 경로 엔트리를 추가해주면 가능하다.

1. 인터넷 게이트웨이

인터넷과 통신하기 위한 경로를 인터넷 게이트웨이라고 부른다.

Routing table 에 등록된 인터넷 게이트웨이를 통해 통신한다.

1. 가상 프라이빗 게이트웨이

인터넷을 경유하지만 프라이빗과 프라이빗 간의 안전한 게이트웨이인

VPN 터널을 구성한다.

VPG(가상 프라이빗 게이트웨이) 와 온프로미스 서버의 끝점이 연결…

AWS 에서는 온프로미스 센터와 VPC 간의 실제 물리적인 사설망을 만들 수 있다. 이를 `AWS Direct Connect` 를 만들 수 있다.

AWS 사업자 중, DX 파트너사가 물리적 네트워크를 연결하는 끝 점에 VPC 의 끝점에 가상 프라이빗 게이트웨이와 연결한다.

대신 고객사에서 AWS 의 DX사의 위치(가산/기흥)까지 물리적 네트워크를 연결한다.

같은 AWS 서비스의 VPC 와 통신

- VPC 피어링을 요청하면 VPC 02 가 VPC 01 로 부터의 요청을 승인. 또한 VPC 01 이 VPC 02 의 요청을 승인하면 양방향 통신이 가능해진다.

VPC 가 너무 많아서  VPC 간의 연결 피어링이 너무 많으면 중앙에 트랜지트 게이트를 만들어서 공유하는 지점을 만든다. 

### 네트워크 엑세스 제어 목록 및 보안 그룹

경로가 존재한다고 해서 아무나 해당 경로를 통해 연결해도 되는가? 아니다!

네트워크를 경유한 트래픽-패킷-이 우리가 정의한 규칙에 비교해서 권한이 있는 패킷인지를 검증해야 한다.

이를 네트워크 방화벽이라고 한다.

VPC 에도 방화벽이 필요하다.

- 네트워크 엑세스 컨트롤 리스트(ACL)
- 보안 그룹

**네트워크 엑세스 제어 목록**

- 서브넷의 가상 방화벽.
- 같은 서브넷에 있는 통신을 제어할 수는 없다.
- 서브넷이 만들어지면 기본으로 만들어진다. 들어오는 인바운드 규칙도 없고, 아웃바운드 규칙도 정의하지 않았다면, 기본적으로 입출입이 가능하다.
    
    즉, NACL 는 기본적으로 규칙이 없다면 모두 허용한다. 따라서 반드시 거절하려는 트래픽-패킷-을 설정해주어야 한다.
    

**보안 그룹**

- 인스턴스의 가상 방화벽
- 워크로드 별로 보안을 확인하는 방화벽
- 기본적으로 보안그룹은 규칙이 없다면 인바운드 트래픽을 거부한다. 다만 통신을 위해선 반드시 허용하는 트래픽을 설정하는 설정이 필요하다. 다만 아웃바운드는 모두 허용한다.
- `state full`! 보안그룹은 들어오는 패킷에 대해 내린 이전 결정을 기억한다(입장 시 허락했다면 나가는 것은 기본적으로 모두 허용!)

### 스토리지 및 데이터베이스(영역3)

## 스토리지

스토리지의 종류

- block 스토리지
- file 스토리지
- object 스토리지

1. Bock 스토리지(== Disk)

블록 스토리지에서 파일은 동일한 크기의 데이터 조각(블록)으로 구분된다. 

EC2에 설치된 OS가 블록을 만들고, 데이터를 어느 블록에 저장하고, 읽어온다.

EC2 가 가지는 디스크를 `EBS` (Elastic Block Storage) 라고 한다.

어플리케이션은 파일을 블록 스토리지에 저장하지만, 해당 파일이 어디에 있는지는 모른다. 어플리케이션은 OS 에 파일을 요청하고, OS 가 파일을 찾아서 어플리케이션에게 전달한다.

그렇기 때문에 만약 OS 가 부팅이 안되면, 해당 디스크만 분리해서 동일한 OS 를 사용하는 EC2 에 붙이면 해당 블록 스토리지를 복구할 수 있다. 그말은 즉은 `EBS`는 영구 스토리지이다.

1. file 스토리지

하나 이상의 서버가 네트워크를 통해서 모두가 엑세스할 수 있는 데이터를 저장하고 싶다. 즉 여러 클라이언트가 공유 파일 폴더에 저장된 데이터에 액세스할 수 있다. 다른말로 네트워크 스토리지, file sharing server 등 다양하게 부른다.

NFS 서버나 SMB 를 만들고, 해당 서버의 네트워크를 각자의 클라이언트의 폴더에 마운트 시킨다.

파일 스토리지 역시 OS 를 통해서 파일 스토리지에 접근한다. 어플리케이션은 알 수 없다. 

NFS 서버 : `EFS` 

window 서버 : `SMB`

VPC 안에 같은 리전에 있을 때, 여러 가용 영역에 걸쳐 데이터를 공유하고 저장할 수 있다. 대신 다른 리전이나 다른 VPC 에 있을 경우는 불가능하다.

1. Object 스토리지

a.txt 파일에 내가 원하는 데이터 있다면, 어플리케이션은 해당 파일의 데이터에 접근하고 있다. 하지만 해당 파일의 위치를 알고 있는 건 OS 이다.

어플리케이션이 해당 파일에 직접 액세스 할 수 있도록 하고 싶다. http 라는 프로토콜의 URI 를 통해서 액세스할 수 있는 위치값을 주자. http 프로토콜을 가지고 해당 파일의 위치를 찾아가자. 

Object 는 데이터 뿐만 아니라, 데이터의 위치(URI) 정보, 키(암호화 되어 있다면!)  등이 담긴 객체이다.

AWS 에는 S3(Simple Storage Service) 가 있다. S3 라는 스토리지는 나의 객체를 담는 버킷을 담고, 객체마다 접근할 수 있는 경로 정보가 만들어진다. 경로 정보를 통해 객체를 접근할 수 있는 권한을 설정한다. 

어떤 객체는 접근이 잦아서 빠르게 찾아가고 싶다.

어떤 객체는 굉장히 중요한 데이터라 훼손을 막고 싶다.

어떤 객체는 용량은 큰데 거의 접근하지도 않는다.

…

스토리지는 사용하는 용량 단위로 금액이 요청된다. 

이러한 부분들을 고려해서 S3 는 다양한 스토리지 클래스를 제공한다. 그 중에서 객체의 상태에 맞춰서 선택하면 된다.

종류(위로 올라갈수록 비싸지고 성능도 좋음)

- 스탠다드 : 가장 빠르고 3개의 복사본이 유지되기 때문에 내구성도 좋다.
- 스탠다드 infrequency : 자주 액세스 하지 않는 데이터
- 원 존 infrequency : 단일 가용 영역에 데이터를 저장
- Intelligent-tiering : AWS 가 대신 객체에 대한 접근 패턴을 분석해서 적합한 클래스로 변환함
- Glacier : 데이터 아키이빙을 위한 저비용 스토리지. 몇 분에서 몇 시간 이내 검색
- Glacier Deep Archive : 매우 저렴한 객체 스토리지. 12시간 이내에 검색

## 데이터베이스

데이터베이스를 만드는 방법에는 2가지가 존재한다.

1. EC2를 만들고, 직접 데이터베이스 서버를 구성하는 방식
    
    이 경우, DB 를 구축하기 이전의 인프라 부분도 직접 생성 및 관리해야 한다.
    
2. AWS 가 제공하는 서비스를 이용하는 방식
    
    ex) RDS(RDMS) / DynamoDB(NOSQL) / DocumentDB(문서) / Naptune(그래프)
    

## RDS

- AWS 클라우드에서 RDMS 를 운영하고 규모를 조정
- 관리작업을 자동화
- 데이터를 안정하게 저장 및 전송

RDS 에서 지원하는 DB 엔진: Aurora, PostgreSQL, MySQL, MariaDB, Oracle, ms-server

### DynamoDB

- 키-값 DB
- 용량 변경에 따라 자동으로 확장/축소 되어 일관된 성능을 유지
- 하루에 10조 개 이상의 요청이 처리할 수 있도록 설계되어 있다.

그 외에도 목적 기반의 다양한 데이터베이스 서비스를 제공하고 있다.

### 보안(영역2)

글로벌 인프라 위에 배포된 다양한 서비스(ec2, db, s3, storage, vpc…)가 과연 안전한지 보안에 취약하지 않았으면 좋겠고, 누군가가 해당 서비스에 엑세스할 때 반드시 `인증` 받은 사용자만이 인증 받은 권한으로 `인가`받아서 업무를 진행했으면 좋겠다.

### 공동책임모델

모든 책임은 고객+AWS 가 함께 진다. 즉 각자가 책임을 지게 되는 영역이 있다.

일반적으로 물리적인 글로벌 인프라(리전, 가용영역, 엣지 로케이션, 가상화) 부분은 AWS가 지지만, VHM 위에서 고객이 생성한 부분에 대해서는 고객의 책임이 될 수 있다.

### Identity and Access mangement(IAM)

인증과 인가를 중앙에서 관리해주는 서비스

보안 주체 : AWS 서비스와 리소스에 액세스를 하려는 주체

- IAM 사용자 : AWS 서비스 및 리소스와 상호작용하는 사람 또는 애플리케이션
- IAM 그룹 : IAM 사용자의 모음
- IAM 역할 : 임시로 권한에 액세스를 하기 위해 수임할 수 있는 자격 증명. 이 역할의 유효기간을 명시하고, 해당 기간동안만 액세스해서 작업을 수행할 수 있는 증명

보안 주체는 내가 사용한 access key 나 MFA 등을 통해 자격 증명을 거친다. 

장기 자격 증명은 IAM 사용자의 이름과 비밀번호로 접근하는 경우를 의미한다.

임시 자격 증명은 access key 에 대해서 24시간 동안만 접근을 허용하는 경우를 의미한다.

인증은 보안 주제와 자격 증명을 중앙에서 관리하겠다는 의미이다.

인증을 받은 보안 주체는 `인가` 를 받아야 한다. 이 보안 주체가 인증을 통해 클라우드에 들어오면, 그 다음은 해당 작업을 할 수 있는 권한이 존재하는 지 확인이 필요하다.

IAM 정책(권한 정책) : AWS 서비스 및 리소스에 대한 권한을 허용하거나 거부하는 문서.

사용자 단일에게 부여할 수도 있고, 그룹 단위로 부여할 수도 있고, IAM 역할에게 정책을 부여할 수도 있다.

**Root 계정** 은 굉장히 중요하고, 엄격하게 다루어야 한다.  그렇기 때문에 사용자를 생성할 때를 제외하고는 가능하면 접근을 제한하는 것을 권장한다. 또한 단순히 패스워드를 통한 로그인을 권장하지 않고, MFA 를 사용해서 안전하게 접근하는 것을 추천한다.

**MFA**

AWS 에서는 `Multi-Factor Authentication` 을 통해서 계정에 추가적인 보호 계층을 제공한다.

### 모니터링 및 분석(영역3)

## CloudWatch

EC2 의 CPU 사용량을 보고 싶어

RDS 의 I/O 건수를 알고 싶어

Storage 의 얼만큼의 용량을 사용했는지 알고 싶어… 

이러한 것들은 모두 해당 서비스의 성능을 확인하려는 것

CloudWatch

- AWS 및 온프레미스에서 실시간으로 인프라 및 리소스를 모니터링
- 단일 위치에서 모든 지표에 엑세스 가능하다(중앙에서 누구나 보고 확인할 수 있도록 대시보드에서 제시해준다)
- 지표에 대해서 이상이 발생했을 때 자동 알림 및 작업을 구성할 수 있음

### CloudTrail

AWS 의 리소스에 접근한다는 것은 AWS 의 API 를 사용한다는 것! 

누가, 언제, 어떤 방법을 통해서 EC2 와 같이 현재 사용중인 서비스에 변화가 발생했는지. 즉, 해당 서비스의 로그을 확인해보고자 한다.

이러한 부분을 제공하는 서비스를 `CloudTrail` 이라고 한다.

- AWS 인프라 전체에 걸쳐 사용자 활동 및 API 요청 추적
- API 호출로 생성된 로그를 필터링하여 운영 분석 및 문제 해결을 지원
- 비정상적 계정 활동을 자동 감지

### Trusted Advisor

사용자가 배포한 워크로드, 어플리케이션이 잘 배포되었는지를 확인하고자 한다.

1. 비용 최적화되고 있는지
2. 성능은 최선의 상태인지
3. 보안에 문제는 없는지
4. 안정적으로 배포 중인지
5. Limit(서비스 한도)에 얼마나 도달했는지

### 요금 및 지원(영역4)

## AWS 요금 개념

- 종량 과금제
- 예약을 통한 비용 절감
- 볼륨 기반 할인 적용 : 스토리지 같은 경우 용량의 사용량이 많을 경우 추가적으로 할인을 적용해주는 개념
    
    ex) 1~100 gb 까지는 0.04달러, 101~1tb 는 0.02달러, 1tb~10tb 까지는 … 이런 식으로 차등적으로 가격을 적용하는 개념
    

리소스를 사용하기 전 예상 금액을 계산해볼 수 있도록 요금 계산기를 제공한다.

## Support 플랜

회원가입과 동시에 Basic 플랜에 가입되게 되지만, 큰 도움이 되지는 않는다.

### 마이그레이션 및 혁신(영역4)